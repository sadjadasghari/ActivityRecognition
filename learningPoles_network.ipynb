{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2\n",
    "# import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import struct\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "# from scipy import ndimage\n",
    "from numpy import linalg as LA\n",
    "from IPython.display import display, Image\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "# Load synthetic dataset\n",
    "num_classes = 3\n",
    "\n",
    "# 60 samples\n",
    "#X = h5py.File('/Users/angelsrates/Documents/PhD/Robust Systems Lab/Activity Recognition/Code/poles_data.mat')\n",
    "#y = h5py.File('/Users/angelsrates/Documents/PhD/Robust Systems Lab/Activity Recognition/Code/poles_y.mat')\n",
    "\n",
    "# 300 samples\n",
    "X = scipy.io.loadmat('poles_data2.mat')\n",
    "y = scipy.io.loadmat('poles_y2.mat') #/Users/angelsrates/Documents/PhD/4th Semester/Project/\n",
    "\n",
    "X = X['data']\n",
    "X = np.squeeze(np.transpose(X))\n",
    "y = y['label']\n",
    "y = y - 1\n",
    "y = np.squeeze(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(4294967295)\n",
    "permutation = np.random.permutation(len(X))\n",
    "X = [X[perm] for perm in permutation]\n",
    "y = [y[perm] for perm in permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 50)\n",
      "(225,)\n",
      "(75, 50)\n",
      "(75,)\n"
     ]
    }
   ],
   "source": [
    "#Select training and testing (75% and 25%)\n",
    "y = [int(i) for i in y]\n",
    "X_train = np.asarray(X[:225])\n",
    "y_train = np.asarray(y[:225])\n",
    "X_test = np.asarray(X[225:])\n",
    "y_test = np.asarray(y[225:])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys_par = np.array([[-1, 0.823676337910219, -1], [-1,-1.93592782488463,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    #shape = list((batch_size, 1843200))\n",
    "    shape[0] = batch_size\n",
    "    #shape[1] = 1843200\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index]\n",
    "        #batch_s[i] = np.reshape(load_video(_train[index]), (1,1843200))\n",
    "\n",
    "    return batch_s\n",
    "\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes \n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#alpha = 0.1\n",
    "def np_sparseLoss(y,p,alpha):\n",
    "    #Assume p is real\n",
    "    N = y.shape[0]\n",
    "    k = p.shape[1]\n",
    "    print(p)\n",
    "    W = np.zeros((N,k))\n",
    "    pw_idx = np.arange(1, N+1, 1)\n",
    "    #print(pw_idx.shape)\n",
    "    # Define vocabulary on set of poles\n",
    "    for i in range(k):\n",
    "        W[:,i] = np.power(np.squeeze(np.full((1, N), np.squeeze(p[0,i]))), pw_idx)\n",
    "    # ADMM - Lasso\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(W, y)\n",
    "    linear_model.Lasso(alpha=alpha, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "       normalize=True, positive=False, precompute=False, random_state=None,\n",
    "       selection='cyclic', tol=0.0001, warm_start=False)\n",
    "    coeff = clf.coef_\n",
    "    coeff = np.reshape(coeff, [k,1])\n",
    "    print(coeff)\n",
    "    return coeff\n",
    "\n",
    "#s = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "#c = np_sparseLoss(s,p,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import sparse_ops\n",
    "\n",
    "def coeff_grad(op, grad):\n",
    "    y = op.inputs[0] \n",
    "    p = op.inputs[1]\n",
    "    c = op.outputs[0]\n",
    "    #W_shape = W.get_shape().as_list()\n",
    "    y_shape = y.get_shape().as_list()\n",
    "    p_shape = p.get_shape().as_list()\n",
    "    N = y_shape[0]\n",
    "    K = p_shape[1]\n",
    "    # W Calculation\n",
    "    impulse = []\n",
    "    idx = tf.cast(tf.stack(np.arange(1, N+1, 1)), tf.float64)\n",
    "    for cc in range(K):\n",
    "        impulse.append(tf.pow(tf.tile(p[:,cc], [50], name=None), idx , name=None))\n",
    "    W = tf.cast(tf.reshape(tf.stack(impulse, axis=1), (N,K)), tf.float64)\n",
    "    WW = tf.matrix_inverse(tf.matmul(tf.transpose(W), W))\n",
    "    Wty = tf.matmul(tf.transpose(W), y)\n",
    "    WWc = tf.matmul(WW, c)\n",
    "    output_dW = []\n",
    "    # Grad wrt W\n",
    "    for i in range(N):\n",
    "        for j in range(K):\n",
    "            output_dWty = []\n",
    "            output_dWWc = []\n",
    "            for n in range(K):\n",
    "                gr1 = tf.gradients(Wty[n,:], [W[i,j]])\n",
    "                gr1 = [tf.constant(0, dtype=tf.float64) if t == None else t for t in gr1]\n",
    "                gr2 = tf.gradients(WWc[n,:], [W[i,j]])\n",
    "                gr2 = [tf.constant(0, dtype=tf.float64) if t == None else t for t in gr2]\n",
    "                output_dWty.append(gr1)\n",
    "                output_dWWc.append(gr2)\n",
    "            gr = tf.matmul(WW, tf.subtract(tf.stack(output_dWty), tf.stack(output_dWWc)))\n",
    "            output_dW.append(gr)\n",
    "    dW = tf.reshape(tf.squeeze(tf.stack(output_dW)), [N, K, K])\n",
    "    \n",
    "    # Grad wrt p\n",
    "    grp = []\n",
    "    for k in range(K):\n",
    "        output_dp = []\n",
    "        for i in range(N):\n",
    "            output_dp.append(tf.multiply(tf.reshape(tf.multiply(tf.cast(i, tf.float64), tf.pow(p[0, k],tf.cast(i-1, tf.float64))), [1]), tf.reshape(dW[i,k,:], [K,1])))\n",
    "        grp.append(tf.add_n(output_dp))\n",
    "    dp = tf.stack(grp)\n",
    "    dp_list = []\n",
    "    for j in range(K):\n",
    "        dp_list.append(tf.reduce_sum(tf.multiply(dp[j,:,:], grad)))\n",
    "    dp = tf.reshape(tf.stack(dp_list), [1, K])\n",
    "    print('dc/dp size:', dp.get_shape())\n",
    "    \n",
    "    #dW = tf.reshape(dW, [N*K,K,1])\n",
    "    #dW_list = []\n",
    "    #for j in range(N*K):\n",
    "    #    dW_list.append(tf.reduce_sum(tf.multiply(dW[j,:,:], grad)))\n",
    "    #dW = tf.reshape(tf.stack(dW_list), [N, K])\n",
    "    #print('dc/dW size:', dW.get_shape())\n",
    "    \n",
    "    # Grad wrt y\n",
    "    dy = tf.matmul(WW, tf.transpose(W))\n",
    "    dy_list = []\n",
    "    for j in range(N):\n",
    "        dy_list.append(tf.reduce_sum(tf.multiply(dy[:,j], grad)))\n",
    "    dy = tf.reshape(tf.stack(dy_list), [N, 1])\n",
    "    print('dc/dy size:', dy.get_shape())\n",
    "    \n",
    "    # Grad wrt alpha   \n",
    "    dalpha = tf.matmul(tf.scalar_mul(tf.constant(-1, dtype=tf.float64), WW), tf.sign(c))\n",
    "    dalpha = tf.reduce_sum(tf.multiply(dalpha, grad))\n",
    "    print('dc/dalpha size:', dalpha.get_shape())\n",
    "    \n",
    "    return dy, dp, dalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def py_func(func, inp, Tout, stateful=True, name=None, grad=None):\n",
    "\n",
    "    # Need to generate a unique name to avoid duplicates:\n",
    "    rnd_name = 'PyFuncGrad' + str(np.random.randint(0, 1000000000000000))\n",
    "\n",
    "    tf.RegisterGradient(rnd_name)(grad)\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({\"PyFunc\": rnd_name}):\n",
    "        return tf.py_func(func, inp, Tout, stateful=stateful, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def tf_coeff_grad(y,p,alpha, name=None):\n",
    "\n",
    "    with ops.op_scope([y,p,alpha], name, \"CoeffGrad\") as name:\n",
    "        z = py_func(np_sparseLoss,\n",
    "                        [y,p,alpha],\n",
    "                        [tf.double],\n",
    "                        name=name,\n",
    "                        grad=coeff_grad)  # <-- here's the call to the gradient\n",
    "        return z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'stack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-29f81fd48f89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m }\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpoles_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-29f81fd48f89>\u001b[0m in \u001b[0;36mpoles_net\u001b[0;34m(x, grad)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Real poles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'real1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'real2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'stack'"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "#import control\n",
    "from scipy.signal import step2\n",
    "import math\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.0015\n",
    "#training_iters = 45000\n",
    "batch_size = 1\n",
    "#display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 50\n",
    "n_classes = 3\n",
    "N = 50\n",
    "#dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float64, [n_input, 1])\n",
    "y = tf.placeholder(tf.float64, [1, n_classes])\n",
    "grad = tf.constant(0, dtype=tf.float64)\n",
    "#y = tf.placeholder(tf.int32, [1,1])\n",
    "\n",
    "def index_along_every_row(array, index):\n",
    "    N,_ = array.shape \n",
    "    return array[np.arange(N), index]\n",
    "\n",
    "def build_hankel_tensor(x, nr, nc, N, dim):\n",
    "    cidx = np.arange(0, nc, 1)\n",
    "    ridx = np.transpose(np.arange(1, nr+1, 1))\n",
    "    Hidx = np.transpose(np.tile(ridx, (nc,1))) + dim*np.tile(cidx, (nr,1))\n",
    "    Hidx = Hidx - 1\n",
    "    arr = tf.reshape(x[:], (1,N))\n",
    "    return tf.py_func(index_along_every_row, [arr, Hidx], [tf.float64])[0]\n",
    "\n",
    "def build_hankel(x, nr, nc, N, dim):\n",
    "    cidx = np.arange(0, nc, 1)\n",
    "    ridx = np.transpose(np.arange(1, nr+1, 1))\n",
    "    Hidx = np.transpose(np.tile(ridx, (nc,1))) + dim*np.tile(cidx, (nr,1))\n",
    "    Hidx = Hidx - 1\n",
    "    arr = x[:]\n",
    "    return arr[Hidx]\n",
    "\n",
    "# Create model\n",
    "def poles_net(x,grad):\n",
    "    # Reshape input picture\n",
    "    #x = tf.reshape(x, shape=[-1, , 50, 1])\n",
    "    # Change accordingly\n",
    "    dim = 1\n",
    "    N = 50\n",
    "    num_poles = 2\n",
    "    # Complex poles\n",
    "    #idx = tf.cast(tf.stack(np.arange(1, N+1, 1)), tf.complex128)\n",
    "    #p11 = tf.multiply(tf.cast(tf.sqrt(weights['r11']), tf.complex128), tf.exp(tf.complex(tf.constant(0, tf.float64), weights['theta11'])))\n",
    "    #p12 = tf.multiply(tf.cast(tf.sqrt(weights['r12']), tf.complex128), tf.exp(tf.complex(tf.constant(0, tf.float64), -weights['theta12'])))\n",
    "    #p21 = tf.multiply(tf.cast(tf.sqrt(weights['r21']), tf.complex128), tf.exp(tf.complex(tf.constant(0, tf.float64), weights['theta21'])))\n",
    "    #p22 = tf.multiply(tf.cast(tf.sqrt(weights['r22']), tf.complex128), tf.exp(tf.complex(tf.constant(0, tf.float64), -weights['theta22'])))   \n",
    "    #y11 = tf.pow(tf.tile(p11, [50], name=None), idx , name=None)\n",
    "    #y12 = tf.pow(tf.tile(p12, [50], name=None), idx, name=None)\n",
    "    #y21 = tf.pow(tf.tile(p21, [50], name=None), idx, name=None)\n",
    "    #y22 = tf.pow(tf.tile(p22, [50], name=None), idx, name=None)\n",
    "    #W = tf.cast(tf.reshape(tf.stack([y11, y21, y12, y22], 1), (N,4)), tf.float64)\n",
    "    \n",
    "    # Real poles\n",
    "    idx = tf.cast(tf.stack(np.arange(1, N+1, 1)), tf.float64)\n",
    "    p1 = weights['real1']\n",
    "    p2 = weights['real2']\n",
    "    p3 = weights['real3']\n",
    "    p = tf.stack([p1, p2, p3], 1)\n",
    "    \n",
    "    #alpha = tf.constant([0.1])\n",
    "    alpha = weights['alpha']\n",
    "    #a = tf.matmul(W, W, adjoint_a=True)\n",
    "    #c = tf.matrix_inverse(tf.cast(a, tf.float64), adjoint=False, name=None)\n",
    "    #coeff = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(tf.transpose(W), W)), tf.transpose(W)), tf.reshape(x, (N,1)))\n",
    "    #alpha_ind = tf.reshape(tf.stack([alpha_ind1, alpha_ind2]), (1,2))\n",
    "    #coeff = tf.matrix_solve_ls(W, tf.reshape(x, (N,1)), fast=False, l2_regularizer=0.002, name=None)\n",
    "    #x = tf.cast(tf.reshape(x, (N,1)), tf.complex128)\n",
    "    #coeff = tf.transpose(coeff)\n",
    "    coeff = tf_coeff_grad(x,p,alpha)\n",
    "    print(coeff)\n",
    "    out = tf.add(tf.matmul(tf.transpose(tf.cast(coeff, tf.float32)), weights['out']), biases['out'])\n",
    "    return [coeff, out]\n",
    "\n",
    "weights = {\n",
    "    'r11': tf.Variable(tf.random_uniform([1], minval=(0.02)**2, maxval=(1)**2, dtype=tf.float64)), # Complex poles\n",
    "    'r12': tf.Variable(tf.random_uniform([1], minval=(0.02)**2, maxval=(1)**2, dtype=tf.float64)),\n",
    "    'theta11': tf.Variable(tf.random_uniform([1], minval=0, maxval=math.pi, dtype=tf.float64)),\n",
    "    'theta12': tf.Variable(tf.random_uniform([1], minval=0, maxval=math.pi, dtype=tf.float64)),\n",
    "    'r21': tf.Variable(tf.random_uniform([1], minval=(0.02)**2, maxval=(1)**2, dtype=tf.float64)),\n",
    "    'r22': tf.Variable(tf.random_uniform([1], minval=(0.02)**2, maxval=(1)**2, dtype=tf.float64)),\n",
    "    'theta21': tf.Variable(tf.random_uniform([1], minval=0, maxval=math.pi, dtype=tf.float64)),\n",
    "    'theta22': tf.Variable(tf.random_uniform([1], minval=0, maxval=math.pi, dtype=tf.float64)),\n",
    "    'real1': tf.Variable(tf.random_uniform([1], minval=-1, maxval=1, dtype=tf.float64)), # Real poles\n",
    "    'real2': tf.Variable(tf.random_uniform([1], minval=-1, maxval=1, dtype=tf.float64)),\n",
    "    'real3': tf.Variable(tf.random_uniform([1], minval=-1, maxval=1, dtype=tf.float64)),\n",
    "    'alpha' : tf.Variable(tf.constant(0.1, dtype=tf.float64)),\n",
    "    #'sys_par1': tf.Variable(tf.random_normal([1], dtype=tf.float64)),\n",
    "    #'sys_par2': tf.Variable(tf.random_normal([1], dtype=tf.float64)),\n",
    "    'out': tf.Variable(tf.random_normal([2, n_classes]))\n",
    "}\n",
    "    \n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([1, n_classes]))\n",
    "}\n",
    "\n",
    "[coeff, pred]= poles_net(x,grad)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "#cost = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=pred, onehot_labels=y))\n",
    "#cost = tf.reduce_mean(tf.losses.mean_squared_error(predictions=pred, labels=y))\n",
    "#cost = tf.subtract(pred, labels)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66993978 -0.88625497 -0.51105266]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [1,3], In[1]: [2,3]\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transpose_1, Variable_26/read)]]\n\nCaused by op u'MatMul_1', defined at:\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-29f81fd48f89>\", line 107, in <module>\n    [coeff, pred]= poles_net(x,grad)\n  File \"<ipython-input-12-29f81fd48f89>\", line 82, in poles_net\n    out = tf.add(tf.matmul(tf.transpose(tf.cast(coeff, tf.float32)), weights['out']), biases['out'])\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1765, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [1,3], In[1]: [2,3]\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transpose_1, Variable_26/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-045fa09ac06b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#batch_y = np.reshape(extract_batch_size(y_train,step,batch_size), (1,1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [1,3], In[1]: [2,3]\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transpose_1, Variable_26/read)]]\n\nCaused by op u'MatMul_1', defined at:\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-29f81fd48f89>\", line 107, in <module>\n    [coeff, pred]= poles_net(x,grad)\n  File \"<ipython-input-12-29f81fd48f89>\", line 82, in poles_net\n    out = tf.add(tf.matmul(tf.transpose(tf.cast(coeff, tf.float32)), weights['out']), biases['out'])\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1765, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1454, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/angelsrates/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Matrix size-incompatible: In[0]: [1,3], In[1]: [2,3]\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](transpose_1, Variable_26/read)]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "n_epochs = 10\n",
    "training_iters = X_train.shape[0]*n_epochs\n",
    "display_step = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    train_acc = 0\n",
    "    while step * batch_size <= training_iters:\n",
    "        batch_x = np.reshape(extract_batch_size(X_train,step,batch_size), [50, 1])\n",
    "        batch_y = extract_batch_size(one_hot(y_train),step,batch_size)\n",
    "        #batch_y = np.reshape(extract_batch_size(y_train,step,batch_size), (1,1))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            train_acc += acc \n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print('Final Training Accuracy:', train_acc/(X_train.shape[0]*n_epochs))\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    acc = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        test = np.reshape(X_test[i,:], [50,1])\n",
    "        print(test.shape)\n",
    "        label = np.reshape(y_test[i,:], (1,3))\n",
    "        #label = np.reshape(y_test[i], (1,1))\n",
    "        print(\"Trajectory:\", i, \\\n",
    "            sess.run([coeff], feed_dict={x: test, y: label}))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={x: test, y: label}))\n",
    "        acc += sess.run(accuracy, feed_dict={x: test, y: label})\n",
    "    print('Final Testing Accuracy:', acc/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrix code\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for epoch in xrange(150):\n",
    "            for i in xrange(total_batch):\n",
    "                    train_step.run(feed_dict = {x: train_arrays, y: train_labels})\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: train_arrays, y: train_labels})/total_batch         \n",
    "            if epoch % display_step == 0:\n",
    "                    print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "    #metrics\n",
    "    y_p = tf.argmax(pred, 1)\n",
    "    val_accuracy, y_pred = sess.run([accuracy, y_p], feed_dict={x:test_arrays, y:test_label})\n",
    "\n",
    "    print \"validation accuracy:\", val_accuracy\n",
    "    y_true = np.argmax(test_label,1)\n",
    "    print \"Precision\", sk.metrics.precision_score(y_true, y_pred)\n",
    "    print \"Recall\", sk.metrics.recall_score(y_true, y_pred)\n",
    "    print \"f1_score\", sk.metrics.f1_score(y_true, y_pred)\n",
    "    print \"confusion_matrix\"\n",
    "    print sk.metrics.confusion_matrix(y_true, y_pred)\n",
    "    fpr, tpr, tresholds = sk.metrics.roc_curve(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
