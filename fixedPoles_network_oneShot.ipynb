{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2\n",
    "# import csv\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import struct\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "# from scipy import ndimage\n",
    "from numpy import linalg as LA\n",
    "from IPython.display import display, Image\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "# Load synthetic dataset\n",
    "\n",
    "X = scipy.io.loadmat('/Users/angelsrates/Documents/PhD/4th Semester/Project/poles_data2.mat')\n",
    "y = scipy.io.loadmat('/Users/angelsrates/Documents/PhD/4th Semester/Project/poles_y2.mat')\n",
    "data = X['data']\n",
    "data = np.squeeze(np.transpose(data))\n",
    "#data_noise = X['data_noise']\n",
    "#data_noise = np.squeeze(np.transpose(data_noise))\n",
    "#sys_par = np.squeeze(np.transpose(X['dic_par']))\n",
    "#sys_par = [np.append(np.array([-1]), sys_par[i]) for i in range(sys_par.shape[0])]\n",
    "y = y['label']\n",
    "y = np.squeeze(y - 1)\n",
    "n_classes = max(y) + 1\n",
    "#num_poles = np.squeeze(X['num_poles'])\n",
    "num_poles = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys_par = [[-1,1.39954943237774, -1], [-1,0.411382829503097, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(4294967295)\n",
    "[N, T] = data.shape\n",
    "permutation = np.random.permutation(data.shape[0])\n",
    "data = [data[perm] for perm in permutation]\n",
    "y = [y[perm] for perm in permutation]\n",
    "X = data\n",
    "# If data with noise, change to:\n",
    "# X = data_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size (225, 50)\n",
      "Training Ground-Truth size (225,)\n",
      "Testing data size (75, 50)\n",
      "Testing Ground-Truth size (75,)\n"
     ]
    }
   ],
   "source": [
    "#Select training and testing (75% and 25%)\n",
    "thr = int(N*0.75)\n",
    "y = [int(i) for i in y]\n",
    "X_train = np.asarray(X[:thr])\n",
    "y_train = np.asarray(y[:thr])\n",
    "X_test = np.asarray(X[thr:])\n",
    "y_test = np.asarray(y[thr:])\n",
    "\n",
    "print('Training data size', X_train.shape)\n",
    "print('Training Ground-Truth size', y_train.shape)\n",
    "print('Testing data size', X_test.shape)\n",
    "print('Testing Ground-Truth size', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    #shape = list((batch_size, 1843200))\n",
    "    shape[0] = batch_size\n",
    "    #shape[1] = 1843200\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index]\n",
    "        #batch_s[i] = np.reshape(load_video(_train[index]), (1,1843200))\n",
    "\n",
    "    return batch_s\n",
    "\n",
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes \n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import control\n",
    "from scipy.signal import step2\n",
    "import math\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.0015\n",
    "batch_size = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_input = T\n",
    "#dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float64, [n_input])\n",
    "y = tf.placeholder(tf.float32, [1, n_classes])\n",
    "#labels = tf.placeholder(tf.int32, [1,1])\n",
    "\n",
    "def index_along_every_row(array, index):\n",
    "    N,_ = array.shape \n",
    "    return array[np.arange(N), index]\n",
    "\n",
    "def build_hankel_tensor(x, nr, nc, N, dim):\n",
    "    cidx = np.arange(0, nc, 1)\n",
    "    ridx = np.transpose(np.arange(1, nr+1, 1))\n",
    "    Hidx = np.transpose(np.tile(ridx, (nc,1))) + dim*np.tile(cidx, (nr,1))\n",
    "    Hidx = Hidx - 1\n",
    "    arr = tf.reshape(x[:], (1,N))\n",
    "    return tf.py_func(index_along_every_row, [arr, Hidx], [tf.float64])[0]\n",
    "\n",
    "def build_hankel(x, nr, nc, N, dim):\n",
    "    cidx = np.arange(0, nc, 1)\n",
    "    ridx = np.transpose(np.arange(1, nr+1, 1))\n",
    "    Hidx = np.transpose(np.tile(ridx, (nc,1))) + dim*np.tile(cidx, (nr,1))\n",
    "    Hidx = Hidx - 1\n",
    "    arr = x[:]\n",
    "    return arr[Hidx]\n",
    "\n",
    "# Create model\n",
    "def poles_net(x, sys_par, T, num_poles):\n",
    "    # Operate over single-channel trajectories\n",
    "    # Sampling rates at 0.3\n",
    "    W_col = []\n",
    "    for i in range(num_poles):\n",
    "        sys = control.TransferFunction([1, 0], sys_par[i], 0.3)\n",
    "        [y1, _] = control.matlab.impulse(sys, T=np.arange(T))\n",
    "        y1 = tf.transpose(y1[0,:T])\n",
    "        W_col.append(y1)\n",
    "    W = tf.reshape(tf.stack(W_col, axis=1), (T,num_poles))\n",
    "    coeff = tf.abs(tf.matrix_solve_ls(W, tf.reshape(x, (T,1)), l2_regularizer=0.0, fast=False, name=None))\n",
    "    coeff = tf.transpose(coeff)\n",
    "    out = tf.add(tf.matmul(tf.cast(coeff, tf.float32), weights['out']), biases['out'])\n",
    "    return [coeff, out]\n",
    "\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_poles, n_classes]))\n",
    "}\n",
    "    \n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([1, n_classes]))\n",
    "}\n",
    "\n",
    "[coeff, pred]= poles_net(x, sys_par, T, num_poles)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1.0).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "Iter 1, Minibatch Loss= 0.463941, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 2, Minibatch Loss= 1.239681, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 3, Minibatch Loss= 0.603769, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 4, Minibatch Loss= 0.347242, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 5, Minibatch Loss= 0.234731, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 6, Minibatch Loss= 0.961255, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 7, Minibatch Loss= 0.455640, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 8, Minibatch Loss= 0.563217, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 9, Minibatch Loss= 1.285264, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 10, Minibatch Loss= 0.582287, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 11, Minibatch Loss= 0.341521, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 12, Minibatch Loss= 0.809583, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 13, Minibatch Loss= 1.004590, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 14, Minibatch Loss= 0.583472, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 15, Minibatch Loss= 0.725431, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 16, Minibatch Loss= 0.806262, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 17, Minibatch Loss= 0.434407, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 18, Minibatch Loss= 0.848757, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 19, Minibatch Loss= 0.469512, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 20, Minibatch Loss= 0.984271, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 21, Minibatch Loss= 0.483374, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 22, Minibatch Loss= 0.880904, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 23, Minibatch Loss= 0.478732, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 24, Minibatch Loss= 0.641752, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 25, Minibatch Loss= 0.353856, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 26, Minibatch Loss= 1.147497, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 27, Minibatch Loss= 0.415019, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 28, Minibatch Loss= 0.866643, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 29, Minibatch Loss= 0.459537, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 30, Minibatch Loss= 0.286598, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 31, Minibatch Loss= 0.799974, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 32, Minibatch Loss= 1.140168, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 33, Minibatch Loss= 0.543158, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 34, Minibatch Loss= 0.325723, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 35, Minibatch Loss= 0.906216, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 36, Minibatch Loss= 0.447138, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 37, Minibatch Loss= 1.035016, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 38, Minibatch Loss= 0.699875, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 39, Minibatch Loss= 0.389227, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 40, Minibatch Loss= 0.801426, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 41, Minibatch Loss= 0.454254, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 42, Minibatch Loss= 1.020400, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 43, Minibatch Loss= 0.502000, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 44, Minibatch Loss= 0.302418, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 45, Minibatch Loss= 0.789038, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 46, Minibatch Loss= 0.403638, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 47, Minibatch Loss= 0.256369, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 48, Minibatch Loss= 0.735100, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 49, Minibatch Loss= 0.359189, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 50, Minibatch Loss= 0.239094, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 51, Minibatch Loss= 1.539150, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 52, Minibatch Loss= 0.708792, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 53, Minibatch Loss= 0.390217, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 54, Minibatch Loss= 0.253461, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 55, Minibatch Loss= 0.873586, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 56, Minibatch Loss= 0.413423, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 57, Minibatch Loss= 0.266265, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 58, Minibatch Loss= 0.733020, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 59, Minibatch Loss= 0.365041, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 60, Minibatch Loss= 0.567039, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 61, Minibatch Loss= 1.517102, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 62, Minibatch Loss= 0.422761, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 63, Minibatch Loss= 0.700409, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 64, Minibatch Loss= 0.982554, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 65, Minibatch Loss= 0.536677, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 66, Minibatch Loss= 0.680660, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 67, Minibatch Loss= 0.372864, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 68, Minibatch Loss= 0.696721, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 69, Minibatch Loss= 0.448260, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 70, Minibatch Loss= 1.154996, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 71, Minibatch Loss= 0.434509, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 72, Minibatch Loss= 0.707224, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 73, Minibatch Loss= 0.467155, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 74, Minibatch Loss= 0.577057, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 75, Minibatch Loss= 1.133085, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 76, Minibatch Loss= 0.600918, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 77, Minibatch Loss= 0.732258, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 78, Minibatch Loss= 0.532852, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 79, Minibatch Loss= 0.899406, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 80, Minibatch Loss= 0.489317, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 81, Minibatch Loss= 0.594599, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 82, Minibatch Loss= 0.971860, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 83, Minibatch Loss= 0.620563, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 84, Minibatch Loss= 0.356491, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 85, Minibatch Loss= 0.243714, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 86, Minibatch Loss= 0.923884, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 87, Minibatch Loss= 0.448238, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 88, Minibatch Loss= 0.537822, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 89, Minibatch Loss= 1.207029, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 90, Minibatch Loss= 0.594695, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 91, Minibatch Loss= 0.639803, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 92, Minibatch Loss= 0.358526, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 93, Minibatch Loss= 0.960533, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 94, Minibatch Loss= 0.507585, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 95, Minibatch Loss= 0.940246, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 96, Minibatch Loss= 0.702921, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 97, Minibatch Loss= 0.391209, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 98, Minibatch Loss= 0.840284, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 99, Minibatch Loss= 0.451074, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 100, Minibatch Loss= 0.565299, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 101, Minibatch Loss= 1.121692, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 102, Minibatch Loss= 0.559037, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 103, Minibatch Loss= 0.639604, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 104, Minibatch Loss= 0.527014, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 105, Minibatch Loss= 0.551646, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 106, Minibatch Loss= 0.292865, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 107, Minibatch Loss= 1.209886, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 108, Minibatch Loss= 0.357440, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 109, Minibatch Loss= 0.269383, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 110, Minibatch Loss= 0.881391, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 111, Minibatch Loss= 0.352819, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 112, Minibatch Loss= 1.158737, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 113, Minibatch Loss= 0.563060, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 114, Minibatch Loss= 0.829548, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 115, Minibatch Loss= 0.519594, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 116, Minibatch Loss= 0.623546, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 117, Minibatch Loss= 0.956524, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 118, Minibatch Loss= 0.511581, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 119, Minibatch Loss= 0.802420, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 120, Minibatch Loss= 0.497288, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 121, Minibatch Loss= 0.611742, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 122, Minibatch Loss= 0.500879, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 123, Minibatch Loss= 0.295321, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 124, Minibatch Loss= 0.705819, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 125, Minibatch Loss= 0.362031, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 126, Minibatch Loss= 0.586519, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 127, Minibatch Loss= 0.316460, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 128, Minibatch Loss= 0.213160, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 129, Minibatch Loss= 0.762203, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 130, Minibatch Loss= 0.361925, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 131, Minibatch Loss= 1.519781, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 132, Minibatch Loss= 0.719819, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 133, Minibatch Loss= 0.658635, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 134, Minibatch Loss= 0.571818, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 135, Minibatch Loss= 0.854212, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 136, Minibatch Loss= 0.671991, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 137, Minibatch Loss= 0.629045, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 138, Minibatch Loss= 0.732647, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 139, Minibatch Loss= 0.536206, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 140, Minibatch Loss= 0.558275, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 141, Minibatch Loss= 0.907249, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 142, Minibatch Loss= 0.646963, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 143, Minibatch Loss= 0.643214, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 144, Minibatch Loss= 0.567548, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 145, Minibatch Loss= 0.540049, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 146, Minibatch Loss= 0.523199, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 147, Minibatch Loss= 1.094457, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 148, Minibatch Loss= 0.499743, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 149, Minibatch Loss= 0.634681, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 150, Minibatch Loss= 0.544026, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 151, Minibatch Loss= 0.547785, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 152, Minibatch Loss= 0.447069, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 153, Minibatch Loss= 0.499472, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 154, Minibatch Loss= 1.270538, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 155, Minibatch Loss= 0.447699, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 156, Minibatch Loss= 0.286728, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 157, Minibatch Loss= 0.202111, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 158, Minibatch Loss= 1.066374, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 159, Minibatch Loss= 0.862420, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 160, Minibatch Loss= 0.505655, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 161, Minibatch Loss= 0.738331, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 162, Minibatch Loss= 0.464603, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 163, Minibatch Loss= 0.951215, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 164, Minibatch Loss= 0.483824, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 165, Minibatch Loss= 0.662593, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 166, Minibatch Loss= 0.314592, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 167, Minibatch Loss= 1.029454, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 168, Minibatch Loss= 0.517568, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 169, Minibatch Loss= 0.505875, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 170, Minibatch Loss= 0.298532, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 171, Minibatch Loss= 0.594078, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 172, Minibatch Loss= 0.328982, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 173, Minibatch Loss= 1.302913, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 174, Minibatch Loss= 0.543328, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 175, Minibatch Loss= 0.543470, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 176, Minibatch Loss= 0.316405, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 177, Minibatch Loss= 0.221903, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 178, Minibatch Loss= 0.171013, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 179, Minibatch Loss= 1.306762, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 180, Minibatch Loss= 0.307293, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 181, Minibatch Loss= 0.922967, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 182, Minibatch Loss= 0.382297, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 183, Minibatch Loss= 0.958341, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 184, Minibatch Loss= 0.810431, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 185, Minibatch Loss= 0.378154, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 186, Minibatch Loss= 0.740114, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 187, Minibatch Loss= 0.917753, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 188, Minibatch Loss= 0.469929, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 189, Minibatch Loss= 0.707226, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 190, Minibatch Loss= 0.378031, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 191, Minibatch Loss= 0.902100, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 192, Minibatch Loss= 0.413138, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 193, Minibatch Loss= 0.267017, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 194, Minibatch Loss= 0.194882, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 195, Minibatch Loss= 1.181829, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 196, Minibatch Loss= 0.330686, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 197, Minibatch Loss= 0.227458, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 198, Minibatch Loss= 0.171251, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 199, Minibatch Loss= 0.136918, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 200, Minibatch Loss= 1.110423, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 201, Minibatch Loss= 0.490588, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 202, Minibatch Loss= 1.183172, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 203, Minibatch Loss= 0.694256, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 204, Minibatch Loss= 0.617051, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 205, Minibatch Loss= 0.349825, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 206, Minibatch Loss= 0.982987, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 207, Minibatch Loss= 0.788890, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 208, Minibatch Loss= 0.443035, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 209, Minibatch Loss= 0.215340, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 210, Minibatch Loss= 0.911217, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 211, Minibatch Loss= 0.939210, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 212, Minibatch Loss= 0.491452, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 213, Minibatch Loss= 0.277361, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 214, Minibatch Loss= 0.877555, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 215, Minibatch Loss= 0.829573, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 216, Minibatch Loss= 0.606491, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 217, Minibatch Loss= 0.353288, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 218, Minibatch Loss= 0.238583, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 219, Minibatch Loss= 1.011479, Training Accuracy= 0.00000\n",
      "(1, 3)\n",
      "Iter 220, Minibatch Loss= 0.946479, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 221, Minibatch Loss= 0.540717, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 222, Minibatch Loss= 0.322224, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 223, Minibatch Loss= 0.781166, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 224, Minibatch Loss= 0.428675, Training Accuracy= 1.00000\n",
      "(1, 3)\n",
      "Iter 225, Minibatch Loss= 0.577026, Training Accuracy= 1.00000\n",
      "Final Training Accuracy: 0.831111111111\n",
      "Optimization Finished!\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 0 [array([[ 0.00120007,  0.11607581]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 1 [array([[ 0.00203907,  0.03196732]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 2 [array([[ 0.01348575,  0.09863703]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 3 [array([[ 0.00071774,  0.01000971]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 4 [array([[ 0.01857196,  0.05823872]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 5 [array([[ 0.01228987,  0.0352473 ]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 6 [array([[ 0.03419828,  0.06503714]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 7 [array([[ 0.02436083,  0.12861141]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 8 [array([[ 0.00863014,  0.09303638]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 9 [array([[ 0.00166669,  0.00469922]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 10 [array([[ 0.00098989,  0.00858547]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 11 [array([[ 0.00371153,  0.01278947]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 12 [array([[ 0.00021378,  0.11327218]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 13 [array([[ 0.00521199,  0.02327569]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 14 [array([[ 0.02741555,  0.01303674]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 15 [array([[ 0.00856838,  0.0275471 ]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 16 [array([[ 0.01062127,  0.04000352]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 17 [array([[ 0.02998758,  0.11480355]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 18 [array([[ 0.00563706,  0.00478233]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 19 [array([[ 0.00525052,  0.10177622]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 20 [array([[ 0.00936743,  0.05593889]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 21 [array([[ 0.01076638,  0.08630104]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 22 [array([[ 0.00183383,  0.00365399]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 23 [array([[ 0.00706055,  0.12532617]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 24 [array([[ 0.00349738,  0.02128701]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 25 [array([[ 0.03416735,  0.07437325]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 26 [array([[ 0.0003035 ,  0.01204635]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 27 [array([[ 0.01653969,  0.06458436]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 28 [array([[ 0.00573937,  0.02745138]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 29 [array([[ 0.0013238 ,  0.00540647]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 30 [array([[ 0.02362078,  0.129533  ]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 31 [array([[ 0.00020816,  0.01793105]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 32 [array([[ 0.01273483,  0.13097906]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 33 [array([[ 0.02443493,  0.03062023]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 34 [array([[ 0.00098904,  0.00858996]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 35 [array([[ 0.00772734,  0.01134133]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 36 [array([[ 0.02350317,  0.12966994]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 37 [array([[ 0.00388184,  0.02125189]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 38 [array([[ 0.00176351,  0.00409502]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 39 [array([[ 0.01712882,  0.06421329]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 40 [array([[ 0.00240873,  0.00023385]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 41 [array([[ 0.0020037 ,  0.00256389]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 42 [array([[ 0.01952145,  0.05419986]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 43 [array([[ 0.00582573,  0.05056864]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 44 [array([[ 0.00348968,  0.03616577]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 45 [array([[ 0.00394118,  0.09471852]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 46 [array([[ 0.00243212,  0.00192296]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 47 [array([[ 0.00024679,  0.01175875]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 48 [array([[ 0.00095809,  0.01089896]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 49 [array([[ 0.00972733,  0.08136715]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 50 [array([[ 0.00534892,  0.03062808]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 51 [array([[ 0.0011227,  0.0078599]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 52 [array([[ 0.02222709,  0.13093065]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 53 [array([[ 0.00204245,  0.03969866]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 54 [array([[ 0.00224983,  0.00089532]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 55 [array([[ 0.03370825,  0.0869968 ]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 56 [array([[ 0.03399255,  0.05516811]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 57 [array([[ 0.00194326,  0.033222  ]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 58 [array([[ 0.00577755,  0.12356911]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 59 [array([[ 0.00054139,  0.00923386]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 60 [array([[ 0.00567675,  0.10067397]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 61 [array([[ 0.00263852,  0.00194701]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 62 [array([[ 0.03395788,  0.05419306]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 63 [array([[ 0.00590697,  0.10752671]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 64 [array([[ 0.0001741 ,  0.01062105]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 65 [array([[ 0.00170817,  0.00444214]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 66 [array([[ 0.00560769,  0.07405619]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 67 [array([[ 0.00222715,  0.00105497]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  1.  0.]]\n",
      "Trajectory: 68 [array([[ 0.0018054 ,  0.00383229]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 69 [array([[ 0.01360029,  0.0311651 ]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 70 [array([[ 0.00984878,  0.0200486 ]])]\n",
      "Testing Accuracy: 1.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 71 [array([[ 0.01362587,  0.07693667]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 72 [array([[ 0.01828576,  0.05945615]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 1.  0.  0.]]\n",
      "Trajectory: 73 [array([[ 0.02434735,  0.12863097]])]\n",
      "Testing Accuracy: 0.0\n",
      "[[ 0.  0.  1.]]\n",
      "Trajectory: 74 [array([[ 0.02850949,  0.05849346]])]\n",
      "Testing Accuracy: 1.0\n",
      "Final Testing Accuracy: 0.413333333333\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "n_epochs = 1\n",
    "training_iters = X_train.shape[0]*n_epochs\n",
    "display_step = 1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    train_acc = 0\n",
    "    while step * batch_size <= training_iters:\n",
    "        batch_x = np.squeeze(extract_batch_size(X_train,step,batch_size))\n",
    "        batch_y = extract_batch_size(one_hot(y_train),step,batch_size)\n",
    "        #batch_y = np.reshape(extract_batch_size(y_train,step,batch_size), (1,1))\n",
    "        print(batch_y.shape)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            train_acc += acc \n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print('Final Training Accuracy:', train_acc/(X_train.shape[0]*n_epochs))\n",
    "    print(\"Optimization Finished!\")\n",
    "    acc = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        test = np.squeeze(X_test[i,:])\n",
    "        label = np.reshape(y_test[i,:], (1,n_classes))\n",
    "        #label = np.reshape(y_test[i], (1,1))\n",
    "        print(label)\n",
    "        print(\"Trajectory:\", i, \\\n",
    "            sess.run([coeff], feed_dict={x: test, y: label}))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "            sess.run(accuracy, feed_dict={x: test, y: label}))\n",
    "        acc += sess.run(accuracy, feed_dict={x: test, y: label})\n",
    "    print('Final Testing Accuracy:', acc/X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
